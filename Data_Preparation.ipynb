{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT NOTES TO READ BEFORE RUNNING THE NOTEBOOK\n",
    "\n",
    "### The following instructions are related to the \"notebook variables\" section\n",
    "\n",
    "1. Determine the window size: **WIN_SIZE**\n",
    "2. Determine the user name: **USER**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intention Detection Study: Data preprocessing and Visualization\n",
    "\n",
    "Preprocessing and visualizing IMU and SmartWheel (SW) measurements. Comparing different trials of the same maneuver and comparing different maneuver dynamics & kinematics.\n",
    "\n",
    "Creating the following dictionary of dataframes:\n",
    "- **raw datasets**: importing raw measurements from *Trimmed_Data*\n",
    "- **featured datasets**: adding extra features (average, diff, ratio, rate of change) using IMU/SW left/right measurements\n",
    "- **segmented datasets**: creating variable window sizes from featured datasets\n",
    "- **feature extracted datasets**: extracting features from time windows\n",
    "\n",
    "Notebook outputs:\n",
    "- **Feature_Extracted_Data** is exported and will be used for clustering \n",
    "- plotting raw vs. filtered measurements\n",
    "- plotting all torque/velocity measurements\n",
    "- plotting selected features/extracted-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importing relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.signal import sosfiltfilt, butter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowpass cut-off frequency\n",
    "cut_off_list = [5, 8, 10, 15, 20] \n",
    "cut_off = cut_off_list[0]\n",
    "\n",
    "# choose the window size\n",
    "WIN_SIZE_list = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "WIN_SIZE = WIN_SIZE_list[7]\n",
    "\n",
    "# Choose the study participant from the list\n",
    "USER_list = ['Mahsa', 'Jaimie'] \n",
    "USER = USER_list[0]\n",
    "\n",
    "# determine whether to export featured data or not\n",
    "EXPORT_DATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SW_samp = 240 # smartwheel's sampling frequency\n",
    "IMU_samp = 200 # smartphone's sampling frequency\n",
    "\n",
    "# original measurements and calculated chair velocity\n",
    "data_columns =  ['AngVel_L', 'AngVel_R', 'Chair_LinVel', 'Chair_AngVel', 'Torque_L', 'Torque_R']\n",
    "\n",
    "# Types of maneuvers, placements, and transforms used\n",
    "maneuvers = ['Curb', 'Obstacles15', 'Obstacles35', 'RampA', 'RampD', 'StraightB', 'StraightF', 'Turn90BL',\n",
    "            'Turn90BR', 'Turn90FR', 'Turn90FL', 'Turn180L', 'Turn180R']\n",
    "# trial names\n",
    "trials = ['T1', 'T2', 'T3']\n",
    "\n",
    "# file name extension used when saving files\n",
    "file_name_extension = '_WS'+ str(WIN_SIZE) + '_' + USER + '.csv' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save a dictionary of dataframes to csv files\n",
    "def save_dic(path, dic):\n",
    "    '''\n",
    "    function input: path to save csv files and dictionary of dataframes to be save\n",
    "    '''\n",
    "    for label, dataset in dic.items():\n",
    "        filename = label + file_name_extension\n",
    "        filename = os.path.join(path, filename)\n",
    "        dataset.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Import Torque and velocity data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Find xls files in the following 'Timmed_Data' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the current path of the notebook\n",
    "CURR_PATH = os.path.abspath('.') \n",
    "\n",
    "# Glob all xls files in the folder\n",
    "glob_paths = glob.glob(os.path.join(CURR_PATH, 'Trimmed_Data', USER, '*.xls'))\n",
    "\n",
    "# Keep trials only and remove trim table files\n",
    "dataset_paths = [path for path in glob_paths if 'Table' not in path]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Parsing data into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets as a dictionary of Pandas DataFrames\n",
    "raw_datasets = {}\n",
    "\n",
    "for dataset_path in dataset_paths:\n",
    "    # Parse labels from filenames\n",
    "    dataset_label = os.path.split(dataset_path)[1].split('.')[0]    \n",
    "\n",
    "    # Read from XLS to Pandas\n",
    "    dataset = pd.read_excel(dataset_path)\n",
    "    \n",
    "    # trim excessive datapoints for selected maneuvers\n",
    "    if USER == 'Jaimie' and dataset_label == 'Turn180L_T1':\n",
    "        dataset = dataset[:800]\n",
    "    \n",
    "#     # use a linear velocity threshold to cut excessive stationary measurements\n",
    "#     if 'Turn180' not in dataset_label:\n",
    "#         thresh_axes = 'Chair_LinVel' # indication of state of motion\n",
    "#         STARTUP_THRESH = 0.1 # initial threshold for raw data\n",
    "#         stop_index = dataset[dataset[thresh_axes] > STARTUP_THRESH].index[-1]\n",
    "#         dataset = dataset[:stop_index]\n",
    "    \n",
    "    # update the dictionary of raw datasets\n",
    "    raw_datasets.update({dataset_label: dataset})\n",
    "\n",
    "# get a list of all imported maneuvers/trials\n",
    "dataset_labels = list(raw_datasets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of raw datasets: 23\n",
      "List of raw datasets: ['Obstacles15_T1', 'Obstacles15_T2', 'Obstacles15_T3', 'Obstacles35_T1', 'Obstacles35_T2', 'Obstacles35_T3', 'RampA_T1', 'RampA_T3', 'StraightF_T1', 'StraightF_T2', 'StraightF_T3', 'Turn180L_T1', 'Turn180L_T2', 'Turn180L_T3', 'Turn180R_T1', 'Turn180R_T2', 'Turn180R_T3', 'Turn90FL_T1', 'Turn90FL_T2', 'Turn90FL_T3', 'Turn90FR_T1', 'Turn90FR_T2', 'Turn90FR_T3']\n"
     ]
    }
   ],
   "source": [
    "# check the number of imported datasets and name of all maneuvers/trials\n",
    "print('Number of raw datasets: {}'.format(len(dataset_labels)))\n",
    "print('List of raw datasets: {}'.format(dataset_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>AngVel_L</th>\n",
       "      <th>AngVel_R</th>\n",
       "      <th>Chair_LinVel</th>\n",
       "      <th>Chair_AngVel</th>\n",
       "      <th>Torque_L</th>\n",
       "      <th>Torque_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time  AngVel_L  AngVel_R  Chair_LinVel  Chair_AngVel  Torque_L  \\\n",
       "0  0.000000       0.0  0.016667      0.008333      0.033333      0.18   \n",
       "1  0.004167       0.0  0.016667      0.008333      0.033333      0.20   \n",
       "2  0.008333       0.0  0.016667      0.008333      0.033333      0.25   \n",
       "3  0.012500       0.0  0.016667      0.008333      0.033333      0.28   \n",
       "4  0.016667       0.0  0.016667      0.008333      0.033333      0.28   \n",
       "\n",
       "   Torque_R  \n",
       "0     -0.09  \n",
       "1     -0.21  \n",
       "2     -0.28  \n",
       "3     -0.32  \n",
       "4     -0.32  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset formatting\n",
    "raw_datasets[dataset_labels[0]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OLD VERSION: Not using this anymore] Resample and create resampled_datasets \n",
    "#### Function to downsample SW data and trim signals to have the same time duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_(datasets):\n",
    "    \n",
    "    ''' \n",
    "    input: dictionary of datasets to resample \n",
    "    \n",
    "    determining the length (time duration) of IMU/SW measurements, trim accordingly & adding 'Time' column.\n",
    "        \n",
    "    return a dictionary of dataframes. Each dataframe has features with similar length and sampling frequency (200Hz)\n",
    "    \n",
    "    '''\n",
    "        \n",
    "    resampled_datasets={}\n",
    "    \n",
    "    for label, dataset in datasets.items():\n",
    "        dataset_copy = dataset.copy()\n",
    "        resampled_dataset = pd.DataFrame(columns=dataset.columns.tolist())\n",
    "        \n",
    "        valid_indx_IMU = dataset_copy['Chair_LinVel'].last_valid_index()\n",
    "        IMU_time = np.linspace(0,valid_indx_IMU/IMU_samp, num = valid_indx_IMU)\n",
    "        \n",
    "        valid_indx_SW_L = dataset_copy['Torque_L'].last_valid_index()\n",
    "        valid_indx_SW_R = dataset_copy['Torque_R'].last_valid_index()\n",
    "        valid_indx_SW = min(valid_indx_SW_L, valid_indx_SW_R)\n",
    "        SW_time = np.linspace(0,valid_indx_SW/SW_samp, num = valid_indx_SW)\n",
    "        \n",
    "        # finding the shortest measurement (IMU or SW)\n",
    "        if SW_time[-1] > IMU_time[-1]:\n",
    "            for col in IMU_data:\n",
    "                resampled_dataset[col] = dataset_copy[col][:valid_indx_IMU].copy()\n",
    "                Time = IMU_time.copy()\n",
    "\n",
    "            for col in SW_data:\n",
    "                resamp_num = int(SW_time[-1] * IMU_samp)\n",
    "                col_copy = signal.resample(dataset_copy[col], resamp_num)\n",
    "                resampled_dataset[col] = col_copy[:valid_indx_IMU]\n",
    "            \n",
    "        elif SW_time[-1] < IMU_time[-1]:\n",
    "            for col in SW_data:\n",
    "                resamp_num = int(SW_time[-1] * IMU_samp)\n",
    "                col_copy = dataset_copy[col][:valid_indx_SW]\n",
    "                resampled_dataset[col] = signal.resample(col_copy, resamp_num)\n",
    "                \n",
    "            for col in IMU_data:\n",
    "                valid_len = min(valid_indx_IMU, resamp_num)\n",
    "                resampled_dataset[col] = dataset_copy[col][:valid_len]\n",
    "                Time = IMU_time[:valid_len]\n",
    "\n",
    "        resampled_dataset.insert(0, 'Time', Time)\n",
    "        resampled_datasets.update({label: resampled_dataset})\n",
    "        \n",
    "    return resampled_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Filtering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Butterworth filter implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter each dataset individually\n",
    "filt_datasets = {}\n",
    "\n",
    "for label, dataset in raw_datasets.items():\n",
    "    # Sampling rates are not consistent across all datasets\n",
    "    f_samp = max(SW_samp, IMU_samp)  # sampling frequency (all data upsampled)\n",
    "    f_low = cut_off # lowpass filter cut-off frequency\n",
    "    \n",
    "    # Get normalized frequencies\n",
    "    w_low = f_low / (f_samp / 2) # Nyquist frequecy = f_samp /2 \n",
    "\n",
    "    # Get Butterworth filter parameters (numerator and denominator)\n",
    "    ## The function sosfiltfilt (and filter design using output='sos') should be preferred over filtfilt for most \n",
    "    ## filtering tasks, as second-order sections have fewer numerical problems.\n",
    "    sos = butter(N=2, Wn=w_low, btype='low', output='sos')\n",
    "    \n",
    "    # Number of columns containing data\n",
    "    n_data_col = len(data_columns) # not counting the 'Time' column\n",
    "    \n",
    "    # Filter all the data columns\n",
    "    Time = dataset.pop('Time')\n",
    "    cols = dataset.columns.tolist()\n",
    "    dataset_copy = np.copy(dataset)\n",
    "    \n",
    "    for i in range(n_data_col):\n",
    "        dataset_copy[:, i] = sosfiltfilt(sos, dataset_copy[:, i])\n",
    "    \n",
    "    df = pd.DataFrame(dataset_copy, columns=cols)\n",
    "    df.insert(0, 'Time', Time)\n",
    "        \n",
    "    filt_datasets.update({label: df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets in filtered dictionary 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>AngVel_L</th>\n",
       "      <th>AngVel_R</th>\n",
       "      <th>Chair_LinVel</th>\n",
       "      <th>Chair_AngVel</th>\n",
       "      <th>Torque_L</th>\n",
       "      <th>Torque_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.016959</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.033938</td>\n",
       "      <td>0.155092</td>\n",
       "      <td>-0.086824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004167</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.016333</td>\n",
       "      <td>0.008162</td>\n",
       "      <td>0.032685</td>\n",
       "      <td>0.147437</td>\n",
       "      <td>-0.085972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008333</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.015706</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>0.031432</td>\n",
       "      <td>0.139632</td>\n",
       "      <td>-0.085075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012500</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.015081</td>\n",
       "      <td>0.007536</td>\n",
       "      <td>0.030181</td>\n",
       "      <td>0.131655</td>\n",
       "      <td>-0.083978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.014457</td>\n",
       "      <td>0.007224</td>\n",
       "      <td>0.028933</td>\n",
       "      <td>0.123517</td>\n",
       "      <td>-0.082576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time  AngVel_L  AngVel_R  Chair_LinVel  Chair_AngVel  Torque_L  \\\n",
       "0  0.000000 -0.000009  0.016959      0.008475      0.033938  0.155092   \n",
       "1  0.004167 -0.000010  0.016333      0.008162      0.032685  0.147437   \n",
       "2  0.008333 -0.000010  0.015706      0.007848      0.031432  0.139632   \n",
       "3  0.012500 -0.000010  0.015081      0.007536      0.030181  0.131655   \n",
       "4  0.016667 -0.000009  0.014457      0.007224      0.028933  0.123517   \n",
       "\n",
       "   Torque_R  \n",
       "0 -0.086824  \n",
       "1 -0.085972  \n",
       "2 -0.085075  \n",
       "3 -0.083978  \n",
       "4 -0.082576  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check filtered dataframes\n",
    "print('Number of datasets in filtered dictionary {}'.format(len(filt_datasets)))\n",
    "filt_datasets[dataset_labels[0]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 -  Plotting experimental measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. compare filtered vs. raw datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare filt and resampled-raw data\n",
    "def compare_filt_raw(maneuver):\n",
    "    nrow = len(data_columns)\n",
    "    ncol = 1\n",
    "    \n",
    "    fontsize = 14\n",
    "    \n",
    "    fig, axs = plt.subplots(nrow, ncol, figsize=(10,20), constrained_layout=True)\n",
    "    axs = axs.ravel()\n",
    "    \n",
    "    fig.suptitle(maneuver, fontsize= fontsize *1.2)\n",
    "    \n",
    "    for i, col in enumerate(data_columns):   \n",
    "        \n",
    "        axs[i-1].plot(raw_datasets[maneuver][col], label='raw')\n",
    "        axs[i-1].plot(filt_datasets[maneuver][col], label = 'filt')\n",
    "        axs[i-1].legend(fontsize = fontsize)\n",
    "        axs[i-1].set_ylabel(col, fontsize = fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # compare raw and filtered data \n",
    "# maneuver = dataset_labels[1]\n",
    "# compare_filt_raw(maneuver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. plot all filtered measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting left and right wheels' torque and angular velocity + chair's linear and angular velocity\n",
    "\n",
    "def plot_allData_overlay(datasets, Torque_AngVel_only = False):\n",
    "    \n",
    "    ''' \n",
    "    datasets: dictionary of datasets of the same maneuver to plot \n",
    "    \n",
    "    plotting left/right torque, left/right angular velocity, linear/angular velocity of the chair \n",
    "    for different trials of a certain maneuver\n",
    "    \n",
    "    '''\n",
    "    if Torque_AngVel_only:\n",
    "    \n",
    "        axes = ['Torque_L', 'Torque_R', 'AngVel_L', 'AngVel_R']\n",
    "\n",
    "        ncol = 2\n",
    "        nrow = 1\n",
    "\n",
    "        for label, dataset in datasets.items():\n",
    "            fig, axs = plt.subplots(nrow, ncol, figsize=(15,6), constrained_layout=True, sharex=True)\n",
    "            axs = axs.ravel()\n",
    "\n",
    "            for i in range(2):           \n",
    "                if 'Torque' in axes[2*i]:\n",
    "                    axs[i].plot(dataset['Time'], dataset[axes[2*i]], label='Left wheel')\n",
    "                    axs[i].plot(dataset['Time'], dataset[axes[2*i+1]], label='Right wheel')\n",
    "                    axs[i].set_ylabel('Torque (Nm)',fontsize = 20)\n",
    "                    axs[i].set_xlabel('Time (s)',fontsize = 20)\n",
    "                    axs[i].tick_params(direction='out', labelsize = 20)\n",
    "                    axs[i].legend(fontsize = 18)\n",
    "                    axs[i].grid()\n",
    "\n",
    "                elif 'Ang' in axes[2*i]:\n",
    "                    axs[i].plot(dataset['Time'], dataset[axes[2*i]], label='Left wheel')\n",
    "                    axs[i].plot(dataset['Time'], dataset[axes[2*i+1]], label='Right wheel')\n",
    "                    axs[i].set_ylabel('Angular velocity (rad/s)',fontsize = 20)\n",
    "                    axs[i].set_xlabel('Time (s)',fontsize = 20)\n",
    "                    axs[i].tick_params(direction='out', labelsize = 20)\n",
    "                    axs[i].legend(fontsize = 18, loc='lower right')\n",
    "                    axs[i].grid()\n",
    "\n",
    "                    # set the x lim\n",
    "                    axs[i].set_xlim(0, dataset[\"Time\"].iloc[-1])\n",
    "\n",
    "                fig.suptitle(label, fontsize = 30, verticalalignment = 'top')  \n",
    "                \n",
    "#             save_name = os.path.join(CURR_PATH, 'imgs',  label + '_' + USER + '_Torque_AngVel_only' + '.png')\n",
    "#             plt.savefig(save_name)\n",
    "                \n",
    "    else:\n",
    "        axes = ['Torque_L', 'Torque_R', 'AngVel_L', 'AngVel_R', 'Chair_LinVel', 'Chair_AngVel']\n",
    "\n",
    "        ncol = 1\n",
    "        nrow = 3\n",
    "\n",
    "        for label, dataset in datasets.items():\n",
    "            fig, axs = plt.subplots(nrow, ncol, figsize=(10,10), constrained_layout=True, sharex=True)\n",
    "            axs = axs.ravel()\n",
    "\n",
    "            for i in range(3):           \n",
    "                if 'Torque' in axes[2*i]:\n",
    "                    axs[i].plot(dataset['Time'], dataset[axes[2*i]], label=axes[2*i])\n",
    "                    axs[i].plot(dataset['Time'], dataset[axes[2*i+1]], label=axes[2*i+1])\n",
    "                    axs[i].set_ylabel('Nm')\n",
    "                    axs[i].legend()\n",
    "                    axs[i].grid()\n",
    "\n",
    "                elif 'Ang' in axes[2*i]:\n",
    "                    axs[i].plot(dataset['Time'], dataset[axes[2*i]], label=axes[2*i])\n",
    "                    axs[i].plot(dataset['Time'], dataset[axes[2*i+1]], label=axes[2*i+1])\n",
    "                    axs[i].set_ylabel('rad/s')\n",
    "                    axs[i].legend()\n",
    "                    axs[i].grid()\n",
    "\n",
    "                elif 'Lin' in axes[2*i]:\n",
    "                    axs2 = axs[i].twinx()  # instantiate a second axes that shares the same x-axis\n",
    "                    lns1 = axs[i].plot(dataset['Time'], dataset[axes[2*i]], label=axes[2*i])\n",
    "                    lns2 = axs2.plot(dataset['Time'], dataset[axes[2*i+1]], label=axes[2*i+1], color ='#ff7f0e')\n",
    "                    axs[i].set_ylabel('m/s')\n",
    "                    axs[i].set_xlabel('Time(s)')\n",
    "                    axs2.set_ylabel('rad/s')\n",
    "\n",
    "                    lns = lns1+lns2\n",
    "                    labs = [l.get_label() for l in lns]\n",
    "                    axs[i].legend(lns, labs, loc=0)                \n",
    "                    axs[i].grid()\n",
    "\n",
    "                    # set the x lim\n",
    "                    axs[i].set_xlim(0, dataset[\"Time\"].iloc[-1])\n",
    "\n",
    "                fig.suptitle(label, fontsize = 14, verticalalignment = 'top')\n",
    "            \n",
    "#             save_name = os.path.join(CURR_PATH, 'imgs',  label + '_' + USER + '.png')\n",
    "#             plt.savefig(save_name)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # plot kinematic and kinetic measurements of all trials\n",
    "# # determine whether to plot torqu/angular veloicty only or showing linear velocity of the wheelchair too\n",
    "# for maneuver in maneuvers:\n",
    "#     datasets_to_plot = {label: dataset for label, dataset in filt_datasets.items() \n",
    "#                         if maneuver in label}\n",
    "#     plot_allData_overlay(datasets_to_plot, Torque_AngVel_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 -  Add new features (average, difference, ratio, rate of change of left/right torque)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Functions to claculate new features & rate of change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Appends L-R colummns to dataframe. If there is a column ending in \"_L\", there must be a \"_R\" too '''\n",
    "def add_new_features (df):\n",
    "\n",
    "    # For dealing with division by 0 when taking ratio of L/R data\n",
    "    RATIO_OFFSET = 1 \n",
    "    \n",
    "    for col in ['Torque_L','Torque_R']:\n",
    "        df[\"Torque_sum\"] = df['Torque_L'] + df['Torque_R']\n",
    "        df[\"Torque_diff\"] = df['Torque_R'] - df['Torque_L']         \n",
    "#         df.loc[abs(df.Torque_L) > abs(df.Torque_R), 'Torque_ratio'] = df['Torque_R']/(df['Torque_L'] + RATIO_OFFSET)\n",
    "#         df.loc[abs(df.Torque_R) > abs(df.Torque_L), 'Torque_ratio'] = df['Torque_L']/(df['Torque_R'] + RATIO_OFFSET)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''add rate of change of features (columns) in a dataframe'''\n",
    "def add_roc(df, dt):\n",
    "    df_roc = df[['Torque_L','Torque_R']].diff().fillna(0)\n",
    "    df_roc.columns = ['Torque_L_roc', 'Torque_R_roc']\n",
    "    return df.join(df_roc)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Add new features to filtered dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new features to all filtered dataframes\n",
    "featured_datasets = {}\n",
    "for label, dataset in filt_datasets.items():\n",
    "    featured_dataset = add_new_features(dataset.copy())\n",
    "    featured_dataset = add_roc(featured_dataset.copy(), 1/f_samp)\n",
    "    featured_datasets.update({label: featured_dataset})\n",
    "    \n",
    "# Get a list of all features\n",
    "feat_columns = featured_datasets[dataset_labels[0]].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>AngVel_L</th>\n",
       "      <th>AngVel_R</th>\n",
       "      <th>Chair_LinVel</th>\n",
       "      <th>Chair_AngVel</th>\n",
       "      <th>Torque_L</th>\n",
       "      <th>Torque_R</th>\n",
       "      <th>Torque_sum</th>\n",
       "      <th>Torque_diff</th>\n",
       "      <th>Torque_L_roc</th>\n",
       "      <th>Torque_R_roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.016959</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.033938</td>\n",
       "      <td>0.155092</td>\n",
       "      <td>-0.086824</td>\n",
       "      <td>0.068268</td>\n",
       "      <td>-0.241916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004167</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.016333</td>\n",
       "      <td>0.008162</td>\n",
       "      <td>0.032685</td>\n",
       "      <td>0.147437</td>\n",
       "      <td>-0.085972</td>\n",
       "      <td>0.061465</td>\n",
       "      <td>-0.233409</td>\n",
       "      <td>-0.007655</td>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008333</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.015706</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>0.031432</td>\n",
       "      <td>0.139632</td>\n",
       "      <td>-0.085075</td>\n",
       "      <td>0.054556</td>\n",
       "      <td>-0.224707</td>\n",
       "      <td>-0.007805</td>\n",
       "      <td>0.000896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012500</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.015081</td>\n",
       "      <td>0.007536</td>\n",
       "      <td>0.030181</td>\n",
       "      <td>0.131655</td>\n",
       "      <td>-0.083978</td>\n",
       "      <td>0.047677</td>\n",
       "      <td>-0.215633</td>\n",
       "      <td>-0.007976</td>\n",
       "      <td>0.001097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.014457</td>\n",
       "      <td>0.007224</td>\n",
       "      <td>0.028933</td>\n",
       "      <td>0.123517</td>\n",
       "      <td>-0.082576</td>\n",
       "      <td>0.040941</td>\n",
       "      <td>-0.206093</td>\n",
       "      <td>-0.008139</td>\n",
       "      <td>0.001402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time  AngVel_L  AngVel_R  Chair_LinVel  Chair_AngVel  Torque_L  \\\n",
       "0  0.000000 -0.000009  0.016959      0.008475      0.033938  0.155092   \n",
       "1  0.004167 -0.000010  0.016333      0.008162      0.032685  0.147437   \n",
       "2  0.008333 -0.000010  0.015706      0.007848      0.031432  0.139632   \n",
       "3  0.012500 -0.000010  0.015081      0.007536      0.030181  0.131655   \n",
       "4  0.016667 -0.000009  0.014457      0.007224      0.028933  0.123517   \n",
       "\n",
       "   Torque_R  Torque_sum  Torque_diff  Torque_L_roc  Torque_R_roc  \n",
       "0 -0.086824    0.068268    -0.241916      0.000000      0.000000  \n",
       "1 -0.085972    0.061465    -0.233409     -0.007655      0.000853  \n",
       "2 -0.085075    0.054556    -0.224707     -0.007805      0.000896  \n",
       "3 -0.083978    0.047677    -0.215633     -0.007976      0.001097  \n",
       "4 -0.082576    0.040941    -0.206093     -0.008139      0.001402  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check featured dataframes\n",
    "featured_datasets['Obstacles15_T1'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Visualize torque features for all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' visualise added features '''\n",
    "def plt_new_feats(label, df, features):\n",
    "   \n",
    "    fontsize = 14\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12,8), constrained_layout=True)\n",
    "    \n",
    "    fig.suptitle(label, fontsize= fontsize *1.2)\n",
    "    \n",
    "    for feat in features:\n",
    "        if 'avg' in feat:\n",
    "            linewidth = 3\n",
    "        elif 'diff' in feat:\n",
    "            linewidth = 3\n",
    "        elif 'roc' in feat:\n",
    "            linewidth = 3\n",
    "        else:\n",
    "            linewidth = 5\n",
    "            \n",
    "        ax.plot(df[feat], label = feat, linewidth = linewidth)\n",
    "        ax.legend(ncol = 3, fontsize = fontsize)\n",
    "        ax.set_ylabel('Torque (Nm)', fontsize = fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # uncomment to examine different feature sets\n",
    "# for label , dataset in featured_datasets.items():\n",
    "#     plt_new_feats(label, dataset, ['Torque_L', 'Torque_R',  'Torque_sum', 'Torque_diff', 'Torque_L_roc', 'Torque_R_roc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - Data segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_datasets = {}\n",
    "\n",
    "# Trim excess datapoints, then split into windows\n",
    "for label, dataset in featured_datasets.items():\n",
    "    \n",
    "    segmented_dataset = []\n",
    "    \n",
    "    dataset = dataset.drop(['Time'], axis=1)\n",
    "    \n",
    "    for i in range(int(len(dataset)/WIN_SIZE)):\n",
    "        df_ = dataset.iloc[i*WIN_SIZE:(i+1)*WIN_SIZE,:] \n",
    "        segmented_dataset.append(df_)\n",
    "    \n",
    "    segmented_datasets.update({label: segmented_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num windowed datasets: 23\n",
      "Num of windows in first dataset: 39\n",
      "Shape of individual window: (128, 10)\n"
     ]
    }
   ],
   "source": [
    "# Check if its constructed correctly\n",
    "print('Num windowed datasets: {}'.format(len(segmented_datasets)))\n",
    "print('Num of windows in first dataset: {}'.format(len(segmented_datasets[dataset_labels[0]])))\n",
    "print('Shape of individual window: {}'.format(segmented_datasets[dataset_labels[0]][-1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset  Obstacles15_T1: No. of data points 5019 & No. of windows 39 \n",
      "Dataset  Obstacles15_T2: No. of data points 3975 & No. of windows 31 \n",
      "Dataset  Obstacles15_T3: No. of data points 4632 & No. of windows 36 \n",
      "Dataset  Obstacles35_T1: No. of data points 3829 & No. of windows 29 \n",
      "Dataset  Obstacles35_T2: No. of data points 3463 & No. of windows 27 \n",
      "Dataset  Obstacles35_T3: No. of data points 2904 & No. of windows 22 \n",
      "Dataset  RampA_T1: No. of data points 2955 & No. of windows 23 \n",
      "Dataset  RampA_T3: No. of data points 2039 & No. of windows 15 \n",
      "Dataset  StraightF_T1: No. of data points 2767 & No. of windows 21 \n",
      "Dataset  StraightF_T2: No. of data points 2861 & No. of windows 22 \n",
      "Dataset  StraightF_T3: No. of data points 2888 & No. of windows 22 \n",
      "Dataset  Turn180L_T1: No. of data points 1539 & No. of windows 12 \n",
      "Dataset  Turn180L_T2: No. of data points 1881 & No. of windows 14 \n",
      "Dataset  Turn180L_T3: No. of data points 2005 & No. of windows 15 \n",
      "Dataset  Turn180R_T1: No. of data points 1539 & No. of windows 12 \n",
      "Dataset  Turn180R_T2: No. of data points 1539 & No. of windows 12 \n",
      "Dataset  Turn180R_T3: No. of data points 1710 & No. of windows 13 \n",
      "Dataset  Turn90FL_T1: No. of data points 4274 & No. of windows 33 \n",
      "Dataset  Turn90FL_T2: No. of data points 4718 & No. of windows 36 \n",
      "Dataset  Turn90FL_T3: No. of data points 5058 & No. of windows 39 \n",
      "Dataset  Turn90FR_T1: No. of data points 4386 & No. of windows 34 \n",
      "Dataset  Turn90FR_T2: No. of data points 4139 & No. of windows 32 \n",
      "Dataset  Turn90FR_T3: No. of data points 4324 & No. of windows 33 \n"
     ]
    }
   ],
   "source": [
    "# to verify original and generated datasets window sizes\n",
    "for name in segmented_datasets.keys():\n",
    "    print('Dataset  {}: No. of data points {} & No. of windows {} '.format(name, len(featured_datasets[name]), len(segmented_datasets[name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AngVel_L</th>\n",
       "      <th>AngVel_R</th>\n",
       "      <th>Chair_LinVel</th>\n",
       "      <th>Chair_AngVel</th>\n",
       "      <th>Torque_L</th>\n",
       "      <th>Torque_R</th>\n",
       "      <th>Torque_sum</th>\n",
       "      <th>Torque_diff</th>\n",
       "      <th>Torque_L_roc</th>\n",
       "      <th>Torque_R_roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>-0.011058</td>\n",
       "      <td>-0.019949</td>\n",
       "      <td>-0.015504</td>\n",
       "      <td>-0.017782</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>-0.101464</td>\n",
       "      <td>-0.097052</td>\n",
       "      <td>-0.105877</td>\n",
       "      <td>-0.005136</td>\n",
       "      <td>-0.003593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>-0.011151</td>\n",
       "      <td>-0.020130</td>\n",
       "      <td>-0.015640</td>\n",
       "      <td>-0.017957</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.105376</td>\n",
       "      <td>-0.105349</td>\n",
       "      <td>-0.105404</td>\n",
       "      <td>-0.004385</td>\n",
       "      <td>-0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>-0.011202</td>\n",
       "      <td>-0.020285</td>\n",
       "      <td>-0.015743</td>\n",
       "      <td>-0.018167</td>\n",
       "      <td>-0.003446</td>\n",
       "      <td>-0.109550</td>\n",
       "      <td>-0.112996</td>\n",
       "      <td>-0.106104</td>\n",
       "      <td>-0.003474</td>\n",
       "      <td>-0.004174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>-0.011200</td>\n",
       "      <td>-0.020408</td>\n",
       "      <td>-0.015804</td>\n",
       "      <td>-0.018416</td>\n",
       "      <td>-0.005867</td>\n",
       "      <td>-0.113877</td>\n",
       "      <td>-0.119744</td>\n",
       "      <td>-0.108011</td>\n",
       "      <td>-0.002421</td>\n",
       "      <td>-0.004327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>-0.011136</td>\n",
       "      <td>-0.020491</td>\n",
       "      <td>-0.015813</td>\n",
       "      <td>-0.018709</td>\n",
       "      <td>-0.007092</td>\n",
       "      <td>-0.118196</td>\n",
       "      <td>-0.125288</td>\n",
       "      <td>-0.111104</td>\n",
       "      <td>-0.001225</td>\n",
       "      <td>-0.004319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AngVel_L  AngVel_R  Chair_LinVel  Chair_AngVel  Torque_L  Torque_R  \\\n",
       "123 -0.011058 -0.019949     -0.015504     -0.017782  0.004413 -0.101464   \n",
       "124 -0.011151 -0.020130     -0.015640     -0.017957  0.000028 -0.105376   \n",
       "125 -0.011202 -0.020285     -0.015743     -0.018167 -0.003446 -0.109550   \n",
       "126 -0.011200 -0.020408     -0.015804     -0.018416 -0.005867 -0.113877   \n",
       "127 -0.011136 -0.020491     -0.015813     -0.018709 -0.007092 -0.118196   \n",
       "\n",
       "     Torque_sum  Torque_diff  Torque_L_roc  Torque_R_roc  \n",
       "123   -0.097052    -0.105877     -0.005136     -0.003593  \n",
       "124   -0.105349    -0.105404     -0.004385     -0.003912  \n",
       "125   -0.112996    -0.106104     -0.003474     -0.004174  \n",
       "126   -0.119744    -0.108011     -0.002421     -0.004327  \n",
       "127   -0.125288    -0.111104     -0.001225     -0.004319  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check a window of the first dataframe\n",
    "segmented_datasets[dataset_labels[0]][0].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AngVel_L',\n",
       " 'AngVel_R',\n",
       " 'Chair_LinVel',\n",
       " 'Chair_AngVel',\n",
       " 'Torque_L',\n",
       " 'Torque_R',\n",
       " 'Torque_sum',\n",
       " 'Torque_diff',\n",
       " 'Torque_L_roc',\n",
       " 'Torque_R_roc']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_columns = segmented_datasets[dataset_labels[0]][0].columns.tolist()\n",
    "featured_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 - Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Feature extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction functions\n",
    "\n",
    "'''L2 norm of an array'''\n",
    "def l2norm(array):\n",
    "    return np.linalg.norm(array, ord=2)\n",
    "\n",
    "'''Root mean squared of an array'''\n",
    "def rms(array):\n",
    "    return np.sqrt(np.mean(array ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(datasets, features_dic):\n",
    "    \n",
    "    '''Extract given features from column of each dataset\n",
    "       Converts a dictionary of datasets to a nested dictionary where each dataset has its own dictionary\n",
    "       of axes/directions'''\n",
    "    \n",
    "    # will be updated with a nested dictionary of {label:{data column name:[dataframe with feature extracted columns]}}\n",
    "    feat_datasets = {}\n",
    "    \n",
    "    # Calculate features for each window of each column of each dataset\n",
    "    for label, dataset_list in datasets.items():\n",
    "        \n",
    "        # will be updated with keys as data columns (e.g., 'X Accel') \n",
    "        cols_dic = {}\n",
    "        \n",
    "        # Loop over data columns\n",
    "        for col in featured_columns:\n",
    "                        \n",
    "            # will be updated with keys as extracted feature names (e.g., 'Mean')\n",
    "            feats = {}\n",
    "            \n",
    "            def function_all_windows(function):\n",
    "                featured_column = []\n",
    "\n",
    "                for window in dataset_list:\n",
    "\n",
    "                    # update a list of extracted feature for the ith column \n",
    "                    featured_column.append(function(window[col]))\n",
    "\n",
    "                return featured_column\n",
    "            \n",
    "            # Execute every function over all windows    \n",
    "            for feat_name, feat_func in features_dic.items():\n",
    "\n",
    "                # apply feature extraction to the ith column for all windows\n",
    "                feats.update({feat_name: function_all_windows(feat_func)})\n",
    "\n",
    "            cols_dic.update({col: pd.DataFrame.from_dict(feats)})\n",
    "        \n",
    "        feat_datasets.update({label: cols_dic})\n",
    "\n",
    "    return feat_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Defining time_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time domain feature functions and names\n",
    "## older version of time features\n",
    "# time_features = {'Mean': np.mean, 'Std': np.std,  'Norm': l2norm, \n",
    "#                  'Max': np.amax, 'Min' : np.amin, 'RMS': rms, 'Sum': np.sum} \n",
    "\n",
    "# removed redundent time features\n",
    "time_features = {'Mean': np.mean, 'Std': np.std, \n",
    "                 'Max': np.amax, 'Min' : np.amin, 'RMS': rms} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Creating a dictionary of feature extracted datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array of features of each window for each dataset and direction\n",
    "time_featured_datasets = feature_extraction(segmented_datasets, time_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num datasets: 23\n",
      "Num directions: 10\n",
      "Shape of first dataset first direction: (39, 5)\n"
     ]
    }
   ],
   "source": [
    "# Check if feature data is constructed correctly and print some info\n",
    "print('Num datasets: {}'.format(len(time_featured_datasets)))\n",
    "print('Num directions: {}'.format(len(time_featured_datasets[dataset_labels[0]])))\n",
    "print('Shape of first dataset first direction: {}'.format(time_featured_datasets[dataset_labels[0]]['Torque_L'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>RMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105526</td>\n",
       "      <td>0.063872</td>\n",
       "      <td>0.223900</td>\n",
       "      <td>-0.007092</td>\n",
       "      <td>0.123350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.157521</td>\n",
       "      <td>3.562872</td>\n",
       "      <td>10.241359</td>\n",
       "      <td>-0.006952</td>\n",
       "      <td>6.268500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.780258</td>\n",
       "      <td>1.236512</td>\n",
       "      <td>10.351650</td>\n",
       "      <td>6.496061</td>\n",
       "      <td>8.866899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.704854</td>\n",
       "      <td>2.475081</td>\n",
       "      <td>6.462641</td>\n",
       "      <td>-0.179346</td>\n",
       "      <td>3.666369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.737763</td>\n",
       "      <td>0.752847</td>\n",
       "      <td>-0.114082</td>\n",
       "      <td>-2.559542</td>\n",
       "      <td>1.893832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mean       Std        Max       Min       RMS\n",
       "0  0.105526  0.063872   0.223900 -0.007092  0.123350\n",
       "1  5.157521  3.562872  10.241359 -0.006952  6.268500\n",
       "2  8.780258  1.236512  10.351650  6.496061  8.866899\n",
       "3  2.704854  2.475081   6.462641 -0.179346  3.666369\n",
       "4 -1.737763  0.752847  -0.114082 -2.559542  1.893832"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_featured_datasets[dataset_labels[0]]['Torque_L'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # examine scaled/original extracted features for all datasets\n",
    "# for label_ in dataset_labels:\n",
    "#     for feat in featured_columns:  \n",
    "#         df_test = time_featured_datasets[label_][feat]\n",
    "#         scaled_features = StandardScaler().fit_transform(df_test.values)\n",
    "#         scaled_features_df = pd.DataFrame(scaled_features, index=df_test.index, columns=df_test.columns)\n",
    "        \n",
    "#         for col in list(time_features.keys())[:-1]:\n",
    "#             print(label_, feat, col)\n",
    "#             if col is not 'Norm':\n",
    "#                 plt.plot(df_test[col], label = col)\n",
    "#         plt.legend()    \n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7 - Columning Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_all_columns(columns, append_tag):\n",
    "\n",
    "    '''Append a tag to the end of every column name of a dataframe'''\n",
    "\n",
    "    new_columns = []\n",
    "    \n",
    "    for column in columns:\n",
    "        \n",
    "        new_columns.append(column + ' ' + append_tag)\n",
    "        \n",
    "    return new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_extracted_columns(datasets):\n",
    "\n",
    "    '''Combined directions (axes) of a featured dataset'''\n",
    "\n",
    "    combined_datasets = {}\n",
    "    \n",
    "    for label, dataset in datasets.items():\n",
    "        # Get labels array of first column\n",
    "        df_combined = pd.DataFrame()\n",
    "        \n",
    "        # Append direction name to feature name and combine everything in one frame\n",
    "        for col_label, df in dataset.items():\n",
    "            df_copy = pd.DataFrame(df)\n",
    "            \n",
    "            # Add direction and placement tags\n",
    "            df_copy.columns = append_all_columns(df.columns, col_label)\n",
    "            \n",
    "            df_combined = df_combined.join(df, how='outer')\n",
    "        \n",
    "        combined_datasets.update({label: df_combined})\n",
    "    \n",
    "    return combined_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take time feature data and combine axes columns\n",
    "columned_time_feat_datasets = combine_extracted_columns(time_featured_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mean AngVel_L', 'Std AngVel_L', 'Max AngVel_L', 'Min AngVel_L', 'RMS AngVel_L', 'Mean AngVel_R', 'Std AngVel_R', 'Max AngVel_R', 'Min AngVel_R', 'RMS AngVel_R', 'Mean Chair_LinVel', 'Std Chair_LinVel', 'Max Chair_LinVel', 'Min Chair_LinVel', 'RMS Chair_LinVel', 'Mean Chair_AngVel', 'Std Chair_AngVel', 'Max Chair_AngVel', 'Min Chair_AngVel', 'RMS Chair_AngVel', 'Mean Torque_L', 'Std Torque_L', 'Max Torque_L', 'Min Torque_L', 'RMS Torque_L', 'Mean Torque_R', 'Std Torque_R', 'Max Torque_R', 'Min Torque_R', 'RMS Torque_R', 'Mean Torque_sum', 'Std Torque_sum', 'Max Torque_sum', 'Min Torque_sum', 'RMS Torque_sum', 'Mean Torque_diff', 'Std Torque_diff', 'Max Torque_diff', 'Min Torque_diff', 'RMS Torque_diff', 'Mean Torque_L_roc', 'Std Torque_L_roc', 'Max Torque_L_roc', 'Min Torque_L_roc', 'RMS Torque_L_roc', 'Mean Torque_R_roc', 'Std Torque_R_roc', 'Max Torque_R_roc', 'Min Torque_R_roc', 'RMS Torque_R_roc']\n"
     ]
    }
   ],
   "source": [
    "# get a list of extracted features names\n",
    "feat_data_columns = columned_time_feat_datasets[dataset_labels[0]].columns.tolist()\n",
    "print(feat_data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean AngVel_L</th>\n",
       "      <th>Std AngVel_L</th>\n",
       "      <th>Max AngVel_L</th>\n",
       "      <th>Min AngVel_L</th>\n",
       "      <th>RMS AngVel_L</th>\n",
       "      <th>Mean AngVel_R</th>\n",
       "      <th>Std AngVel_R</th>\n",
       "      <th>Max AngVel_R</th>\n",
       "      <th>Min AngVel_R</th>\n",
       "      <th>RMS AngVel_R</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean Torque_L_roc</th>\n",
       "      <th>Std Torque_L_roc</th>\n",
       "      <th>Max Torque_L_roc</th>\n",
       "      <th>Min Torque_L_roc</th>\n",
       "      <th>RMS Torque_L_roc</th>\n",
       "      <th>Mean Torque_R_roc</th>\n",
       "      <th>Std Torque_R_roc</th>\n",
       "      <th>Max Torque_R_roc</th>\n",
       "      <th>Min Torque_R_roc</th>\n",
       "      <th>RMS Torque_R_roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.004082</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>-0.011202</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>-0.006278</td>\n",
       "      <td>0.009975</td>\n",
       "      <td>0.016959</td>\n",
       "      <td>-0.020491</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001267</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>-0.009010</td>\n",
       "      <td>0.004841</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>-0.004704</td>\n",
       "      <td>0.002346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156533</td>\n",
       "      <td>0.154823</td>\n",
       "      <td>0.510254</td>\n",
       "      <td>-0.011002</td>\n",
       "      <td>0.220165</td>\n",
       "      <td>0.138060</td>\n",
       "      <td>0.132795</td>\n",
       "      <td>0.451677</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>0.191560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080066</td>\n",
       "      <td>0.036060</td>\n",
       "      <td>0.123925</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.087812</td>\n",
       "      <td>0.055259</td>\n",
       "      <td>0.026346</td>\n",
       "      <td>0.089390</td>\n",
       "      <td>-0.004093</td>\n",
       "      <td>0.061218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.959220</td>\n",
       "      <td>0.258138</td>\n",
       "      <td>1.400532</td>\n",
       "      <td>0.517521</td>\n",
       "      <td>0.993347</td>\n",
       "      <td>0.989541</td>\n",
       "      <td>0.303777</td>\n",
       "      <td>1.514055</td>\n",
       "      <td>0.460247</td>\n",
       "      <td>1.035120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029260</td>\n",
       "      <td>0.015377</td>\n",
       "      <td>0.018261</td>\n",
       "      <td>-0.048197</td>\n",
       "      <td>0.033055</td>\n",
       "      <td>0.007441</td>\n",
       "      <td>0.014982</td>\n",
       "      <td>0.038349</td>\n",
       "      <td>-0.016978</td>\n",
       "      <td>0.016728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.742539</td>\n",
       "      <td>0.168123</td>\n",
       "      <td>1.961942</td>\n",
       "      <td>1.407501</td>\n",
       "      <td>1.750631</td>\n",
       "      <td>1.942624</td>\n",
       "      <td>0.159049</td>\n",
       "      <td>2.174619</td>\n",
       "      <td>1.524171</td>\n",
       "      <td>1.949124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051568</td>\n",
       "      <td>0.045239</td>\n",
       "      <td>0.010990</td>\n",
       "      <td>-0.145229</td>\n",
       "      <td>0.068599</td>\n",
       "      <td>-0.062965</td>\n",
       "      <td>0.129354</td>\n",
       "      <td>0.062871</td>\n",
       "      <td>-0.332261</td>\n",
       "      <td>0.143864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.595998</td>\n",
       "      <td>0.158154</td>\n",
       "      <td>1.940253</td>\n",
       "      <td>1.454565</td>\n",
       "      <td>1.603815</td>\n",
       "      <td>2.035406</td>\n",
       "      <td>0.083118</td>\n",
       "      <td>2.187664</td>\n",
       "      <td>1.955051</td>\n",
       "      <td>2.037103</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012962</td>\n",
       "      <td>0.035006</td>\n",
       "      <td>0.028173</td>\n",
       "      <td>-0.090050</td>\n",
       "      <td>0.037329</td>\n",
       "      <td>0.048798</td>\n",
       "      <td>0.043360</td>\n",
       "      <td>0.122884</td>\n",
       "      <td>-0.010715</td>\n",
       "      <td>0.065278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean AngVel_L  Std AngVel_L  Max AngVel_L  Min AngVel_L  RMS AngVel_L  \\\n",
       "0      -0.004082      0.003981      0.000222     -0.011202      0.005702   \n",
       "1       0.156533      0.154823      0.510254     -0.011002      0.220165   \n",
       "2       0.959220      0.258138      1.400532      0.517521      0.993347   \n",
       "3       1.742539      0.168123      1.961942      1.407501      1.750631   \n",
       "4       1.595998      0.158154      1.940253      1.454565      1.603815   \n",
       "\n",
       "   Mean AngVel_R  Std AngVel_R  Max AngVel_R  Min AngVel_R  RMS AngVel_R  ...  \\\n",
       "0      -0.006278      0.009975      0.016959     -0.020491      0.011786  ...   \n",
       "1       0.138060      0.132795      0.451677     -0.020523      0.191560  ...   \n",
       "2       0.989541      0.303777      1.514055      0.460247      1.035120  ...   \n",
       "3       1.942624      0.159049      2.174619      1.524171      1.949124  ...   \n",
       "4       2.035406      0.083118      2.187664      1.955051      2.037103  ...   \n",
       "\n",
       "   Mean Torque_L_roc  Std Torque_L_roc  Max Torque_L_roc  Min Torque_L_roc  \\\n",
       "0          -0.001267          0.004672          0.006754         -0.009010   \n",
       "1           0.080066          0.036060          0.123925          0.000140   \n",
       "2          -0.029260          0.015377          0.018261         -0.048197   \n",
       "3          -0.051568          0.045239          0.010990         -0.145229   \n",
       "4          -0.012962          0.035006          0.028173         -0.090050   \n",
       "\n",
       "   RMS Torque_L_roc  Mean Torque_R_roc  Std Torque_R_roc  Max Torque_R_roc  \\\n",
       "0          0.004841          -0.000245          0.002333          0.003374   \n",
       "1          0.087812           0.055259          0.026346          0.089390   \n",
       "2          0.033055           0.007441          0.014982          0.038349   \n",
       "3          0.068599          -0.062965          0.129354          0.062871   \n",
       "4          0.037329           0.048798          0.043360          0.122884   \n",
       "\n",
       "   Min Torque_R_roc  RMS Torque_R_roc  \n",
       "0         -0.004704          0.002346  \n",
       "1         -0.004093          0.061218  \n",
       "2         -0.016978          0.016728  \n",
       "3         -0.332261          0.143864  \n",
       "4         -0.010715          0.065278  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm formatting\n",
    "columned_time_feat_datasets[dataset_labels[0]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # compare original and scaled extracted features\n",
    "# #create an empty dataframe with columns similar to the imported datasets\n",
    "# df_test = pd.DataFrame(columns=columned_time_feat_datasets[dataset_labels[0]].columns.tolist())\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # combine desired datasets into one dataframe\n",
    "# for label in dataset_labels:\n",
    "#     df_test = pd.concat([df_test, columned_time_feat_datasets[label]], ignore_index=True)\n",
    "\n",
    "# df_test_stand = scaler.fit_transform(df_test.copy())\n",
    "# df_test_stand = pd.DataFrame(df_test_stand, columns=feat_data_columns)\n",
    "\n",
    "# for feat in feat_data_columns:\n",
    "#     plt.plot(df_test[feat], label = 'measurements')\n",
    "#     plt.plot(df_test_stand[feat], label = 'normalized')\n",
    "#     plt.ylabel(feat); plt.legend();\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8 - Saving feature extracted dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(CURR_PATH, 'Feature_Extracted_Data', USER, 'WinSize'+ str(WIN_SIZE))\n",
    "pathlib.Path(path).mkdir(parents=True, exist_ok=True)\n",
    "save_dic(path, columned_time_feat_datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
